{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train Shape:\n",
      "(66173, 105)\n",
      "Label Shape:\n",
      "(66173, 27)\n",
      "       gk_positioning  ls  st  rs  lw  lf  cf  rf  rw  lam  ...  lwb  ldm  \\\n",
      "58423               1   0   0   0   0   0   0   0   0    0  ...    0    0   \n",
      "27281               0   0   0   0   0   0   0   0   0    0  ...    0    1   \n",
      "56728               0   1   1   1   0   0   0   0   0    0  ...    0    0   \n",
      "74616               0   1   1   1   1   1   1   1   1    0  ...    0    0   \n",
      "42736               0   0   0   0   0   0   0   0   0    0  ...    0    0   \n",
      "\n",
      "       cdm  rdm  rwb  lb  lcb  cb  rcb  rb  \n",
      "58423    0    0    0   0    0   0    0   0  \n",
      "27281    1    1    0   0    1   1    1   0  \n",
      "56728    0    0    0   0    0   0    0   0  \n",
      "74616    0    0    0   0    0   0    0   0  \n",
      "42736    0    0    0   1    0   0    0   1  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "['gk_positioning', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb']\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "#Juliana\n",
    "#Logist Regressiion Ensemble Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_labels = pd.read_csv('/Users/julianashihadeh/Desktop/GroupProject/Player_Position_Prediction/FridayVersion/Player_Position_Prediction/train_labels.csv', sep=\",\",header=\"infer\", low_memory = False)         \n",
    "#print(training_labels.head())\n",
    "\n",
    "#Extracting all the training data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "training_data = pd.read_csv('/Users/julianashihadeh/Desktop/GroupProject/Player_Position_Prediction/FridayVersion/Player_Position_Prediction/train1.csv', sep=\",\",header=\"infer\", low_memory=False)\n",
    "#print(training_data.head())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, training_labels, test_size=0.2, random_state=11)\n",
    "\n",
    "print(\"X_Train Shape:\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"Label Shape:\")\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_train.head())\n",
    "\n",
    "#print(y_train)                                                    \n",
    "col_names = y_train.columns.values.tolist()\n",
    "print(col_names)\n",
    "print(len(col_names))\n",
    "\n",
    "#For Training:\n",
    "models = []\n",
    "for i in range(0, 27):\n",
    "    modelname = 'LRModel' + str(i)\n",
    "    #Add code above in here\n",
    "    \n",
    "    #Change the last two lines so they save to separate models\n",
    "    logreg = LogisticRegression(solver='lbfgs', max_iter = 10000)\n",
    "    test_labels = y_train[col_names[i]]\n",
    "    modelname = logreg.fit(X_train, test_labels)\n",
    "    \n",
    "    #At the end, append to the list of models\n",
    "    models.append(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy results and info for player position: gk_positioning\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14695\n",
      "           1       1.00      1.00      1.00      1849\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     16544\n",
      "   macro avg       1.00      1.00      1.00     16544\n",
      "weighted avg       1.00      1.00      1.00     16544\n",
      "\n",
      "Model accuracy results and info for player position: ls\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.979690522244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     14201\n",
      "           1       0.93      0.92      0.93      2343\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     16544\n",
      "   macro avg       0.96      0.96      0.96     16544\n",
      "weighted avg       0.98      0.98      0.98     16544\n",
      "\n",
      "Model accuracy results and info for player position: st\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.979690522244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     14201\n",
      "           1       0.93      0.92      0.93      2343\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     16544\n",
      "   macro avg       0.96      0.96      0.96     16544\n",
      "weighted avg       0.98      0.98      0.98     16544\n",
      "\n",
      "Model accuracy results and info for player position: rs\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.979690522244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     14201\n",
      "           1       0.93      0.92      0.93      2343\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     16544\n",
      "   macro avg       0.96      0.96      0.96     16544\n",
      "weighted avg       0.98      0.98      0.98     16544\n",
      "\n",
      "Model accuracy results and info for player position: lw\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.932422630561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     13434\n",
      "           1       0.83      0.81      0.82      3110\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     16544\n",
      "   macro avg       0.89      0.89      0.89     16544\n",
      "weighted avg       0.93      0.93      0.93     16544\n",
      "\n",
      "Model accuracy results and info for player position: lf\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.940220019342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     15425\n",
      "           1       0.62      0.31      0.41      1119\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.78      0.65      0.69     16544\n",
      "weighted avg       0.93      0.94      0.93     16544\n",
      "\n",
      "Model accuracy results and info for player position: cf\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.940220019342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     15425\n",
      "           1       0.62      0.31      0.41      1119\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.78      0.65      0.69     16544\n",
      "weighted avg       0.93      0.94      0.93     16544\n",
      "\n",
      "Model accuracy results and info for player position: rf\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.940220019342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     15425\n",
      "           1       0.62      0.31      0.41      1119\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.78      0.65      0.69     16544\n",
      "weighted avg       0.93      0.94      0.93     16544\n",
      "\n",
      "Model accuracy results and info for player position: rw\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.932422630561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     13434\n",
      "           1       0.83      0.81      0.82      3110\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     16544\n",
      "   macro avg       0.89      0.89      0.89     16544\n",
      "weighted avg       0.93      0.93      0.93     16544\n",
      "\n",
      "Model accuracy results and info for player position: lam\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.930186170213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     14607\n",
      "           1       0.74      0.61      0.67      1937\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     16544\n",
      "   macro avg       0.85      0.79      0.82     16544\n",
      "weighted avg       0.93      0.93      0.93     16544\n",
      "\n",
      "Model accuracy results and info for player position: cam\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.930186170213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     14607\n",
      "           1       0.74      0.61      0.67      1937\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     16544\n",
      "   macro avg       0.85      0.79      0.82     16544\n",
      "weighted avg       0.93      0.93      0.93     16544\n",
      "\n",
      "Model accuracy results and info for player position: ram\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.930186170213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     14607\n",
      "           1       0.74      0.61      0.67      1937\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     16544\n",
      "   macro avg       0.85      0.79      0.82     16544\n",
      "weighted avg       0.93      0.93      0.93     16544\n",
      "\n",
      "Model accuracy results and info for player position: lm\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.897969052224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     13882\n",
      "           1       0.71      0.62      0.66      2662\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     16544\n",
      "   macro avg       0.82      0.79      0.80     16544\n",
      "weighted avg       0.89      0.90      0.90     16544\n",
      "\n",
      "Model accuracy results and info for player position: lcm\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.948621856867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     15461\n",
      "           1       0.64      0.48      0.55      1083\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.80      0.73      0.76     16544\n",
      "weighted avg       0.94      0.95      0.95     16544\n",
      "\n",
      "Model accuracy results and info for player position: cm\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.948621856867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     15461\n",
      "           1       0.64      0.48      0.55      1083\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.80      0.73      0.76     16544\n",
      "weighted avg       0.94      0.95      0.95     16544\n",
      "\n",
      "Model accuracy results and info for player position: rcm\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.948621856867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     15461\n",
      "           1       0.64      0.48      0.55      1083\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.80      0.73      0.76     16544\n",
      "weighted avg       0.94      0.95      0.95     16544\n",
      "\n",
      "Model accuracy results and info for player position: rm\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.897969052224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     13882\n",
      "           1       0.71      0.62      0.66      2662\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     16544\n",
      "   macro avg       0.82      0.79      0.80     16544\n",
      "weighted avg       0.89      0.90      0.90     16544\n",
      "\n",
      "Model accuracy results and info for player position: lwb\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.937681334623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96     14450\n",
      "           1       0.77      0.73      0.75      2094\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.86      0.85      0.86     16544\n",
      "weighted avg       0.94      0.94      0.94     16544\n",
      "\n",
      "Model accuracy results and info for player position: ldm\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.945478723404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     15061\n",
      "           1       0.72      0.64      0.68      1483\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.84      0.81      0.82     16544\n",
      "weighted avg       0.94      0.95      0.94     16544\n",
      "\n",
      "Model accuracy results and info for player position: cdm\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.945478723404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     15061\n",
      "           1       0.72      0.64      0.68      1483\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.84      0.81      0.82     16544\n",
      "weighted avg       0.94      0.95      0.94     16544\n",
      "\n",
      "Model accuracy results and info for player position: rdm\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.945478723404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     15061\n",
      "           1       0.72      0.64      0.68      1483\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.84      0.81      0.82     16544\n",
      "weighted avg       0.94      0.95      0.94     16544\n",
      "\n",
      "Model accuracy results and info for player position: rwb\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.937681334623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96     14450\n",
      "           1       0.77      0.73      0.75      2094\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.86      0.85      0.86     16544\n",
      "weighted avg       0.94      0.94      0.94     16544\n",
      "\n",
      "Model accuracy results and info for player position: lb\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.924262572534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96     14728\n",
      "           1       0.67      0.61      0.64      1816\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     16544\n",
      "   macro avg       0.81      0.79      0.80     16544\n",
      "weighted avg       0.92      0.92      0.92     16544\n",
      "\n",
      "Model accuracy results and info for player position: lcb\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.970623791103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     12306\n",
      "           1       0.95      0.94      0.94      4238\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     16544\n",
      "   macro avg       0.96      0.96      0.96     16544\n",
      "weighted avg       0.97      0.97      0.97     16544\n",
      "\n",
      "Model accuracy results and info for player position: cb\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.970623791103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     12306\n",
      "           1       0.95      0.94      0.94      4238\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     16544\n",
      "   macro avg       0.96      0.96      0.96     16544\n",
      "weighted avg       0.97      0.97      0.97     16544\n",
      "\n",
      "Model accuracy results and info for player position: rcb\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.970623791103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     12306\n",
      "           1       0.95      0.94      0.94      4238\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     16544\n",
      "   macro avg       0.96      0.96      0.96     16544\n",
      "weighted avg       0.97      0.97      0.97     16544\n",
      "\n",
      "Model accuracy results and info for player position: rb\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.924262572534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96     14728\n",
      "           1       0.67      0.61      0.64      1816\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     16544\n",
      "   macro avg       0.81      0.79      0.80     16544\n",
      "weighted avg       0.92      0.92      0.92     16544\n",
      "\n",
      "Length of all_f1scores and all_accuracies:\n",
      "27\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "#For Testing: \n",
    "all_predictions = []\n",
    "all_f1scores = []\n",
    "all_accuracies = []\n",
    "for i in range(0, 27):\n",
    "    #Select the model\n",
    "    #modelname = 'model' + str(i)\n",
    "    #Test the model. Pass all the test data, not one by one returns labels of all the test data\n",
    "    print(\"Model accuracy results and info for player position: \" + col_names[i])\n",
    "    predictions = models[i].predict(X_test)\n",
    "    test_labels = y_test[col_names[i]]\n",
    "    print(\"The number of values in a test_label:\")\n",
    "    print(len(test_labels))\n",
    "    a = metrics.accuracy_score(test_labels, predictions)\n",
    "    print(\"Accuracy:\",a)\n",
    "    print(classification_report(test_labels, predictions))\n",
    "    f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "    all_f1scores.append(f1)\n",
    "    all_accuracies.append(a)\n",
    "    #Final shape should be 32 X 82717: 32 lists of 82717 length \n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "print(\"Length of all_f1scores and all_accuracies:\")\n",
    "print(len(all_f1scores))\n",
    "print(len(all_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(all_predictions, index = ['gk_positioning', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943170528242\n"
     ]
    }
   ],
   "source": [
    "#Averaging the weighted f1 scores to compute overall f1 score on the entire Logistic Regression Ensemble\n",
    "len(all_f1scores)\n",
    "s = 0.0\n",
    "for i in all_f1scores:\n",
    "    s = s + i\n",
    "final_acc = s / len(all_f1scores)\n",
    "print(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Uncomment when everything is ready \n",
    "df = pd.DataFrame(all_predictions, index = ['gk_diving', 'gk_handling', 'gk_kicking', 'gk_reflexes', 'gk_speed', 'gk_positioning', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb'])\n",
    "\n",
    "#Extracts all the labels for each test case \n",
    "#Based off of Apeksha's Code From Feature Extraction\n",
    "addT = df.T\n",
    "print(addT)\n",
    "labels=addT[addT.apply(lambda x: x == addT.max(axis = 1))] \n",
    "print(labels)\n",
    "\n",
    "classes=[]\n",
    "\n",
    "#Write all labels to this file\n",
    "outputFile = open('SplitTrainTestlogisticregressionensembleclassresults.txt','w')\n",
    "\n",
    "for i in range(labels.shape[0]):\n",
    "    l=list(labels.columns[np.isfinite(labels.iloc[i])])\n",
    "    print(l)\n",
    "    formatted_l=map(lambda x:x+' ', l)\n",
    "    outputFile.writelines(\"ID: \" + str(i) + \", Total Classes: \" + str(len(l)) + \" Classes: \")\n",
    "    outputFile.writelines(formatted_l)\n",
    "    outputFile.writelines('\\n')\n",
    "    #for i in l:\n",
    "    #    outputFile.write(i)\n",
    "    #    outputFile.write('\\n')\n",
    "    classes.append(l)\n",
    "    #Save the classes to a file\n",
    "print(len(classes))\n",
    "print(classes)\n",
    "outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
