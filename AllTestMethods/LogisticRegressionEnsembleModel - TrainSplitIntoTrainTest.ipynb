{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train Shape:\n",
      "(66173, 105)\n",
      "Label Shape:\n",
      "(66173, 27)\n",
      "       gk_positioning  ls  st  rs  lw  lf  cf  rf  rw  lam  ...  lwb  ldm  \\\n",
      "58423               1   0   0   0   0   0   0   0   0    0  ...    0    0   \n",
      "27281               0   0   0   0   0   0   0   0   0    0  ...    0    1   \n",
      "56728               0   1   1   1   0   0   0   0   0    0  ...    0    0   \n",
      "74616               0   1   1   1   1   1   1   1   1    0  ...    0    0   \n",
      "42736               0   0   0   0   0   0   0   0   0    0  ...    0    0   \n",
      "\n",
      "       cdm  rdm  rwb  lb  lcb  cb  rcb  rb  \n",
      "58423    0    0    0   0    0   0    0   0  \n",
      "27281    1    1    0   0    1   1    1   0  \n",
      "56728    0    0    0   0    0   0    0   0  \n",
      "74616    0    0    0   0    0   0    0   0  \n",
      "42736    0    0    0   1    0   0    0   1  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "['gk_positioning', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb']\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "#Juliana\n",
    "#Logist Regressiion Ensemble Model With solver='lbfgs', max_iter = 10000\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_labels = pd.read_csv('/Users/julianashihadeh/Desktop/GroupProject/Player_Position_Prediction/FridayVersion/Player_Position_Prediction/train_labels.csv', sep=\",\",header=\"infer\", low_memory = False)         \n",
    "#print(training_labels.head())\n",
    "\n",
    "#Extracting all the training data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "training_data = pd.read_csv('/Users/julianashihadeh/Desktop/GroupProject/Player_Position_Prediction/SundayVersion/Player_Position_Prediction/train1.csv', sep=\",\",header=\"infer\", low_memory=False)\n",
    "#print(training_data.head())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, training_labels, test_size=0.2, random_state=11)\n",
    "\n",
    "print(\"X_Train Shape:\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"Label Shape:\")\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_train.head())\n",
    "\n",
    "#print(y_train)                                                    \n",
    "col_names = y_train.columns.values.tolist()\n",
    "print(col_names)\n",
    "print(len(col_names))\n",
    "\n",
    "#For Training:\n",
    "models = []\n",
    "for i in range(0, 27):\n",
    "    modelname = 'LRModel' + str(i)\n",
    "    #Add code above in here\n",
    "    \n",
    "    #Change the last two lines so they save to separate models\n",
    "    logreg = LogisticRegression(solver='lbfgs', max_iter = 10000)\n",
    "    test_labels = y_train[col_names[i]]\n",
    "    modelname = logreg.fit(X_train, test_labels)\n",
    "    \n",
    "    #At the end, append to the list of models\n",
    "    models.append(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "#For Testing: \n",
    "all_predictions = []\n",
    "all_f1scores = []\n",
    "all_accuracies = []\n",
    "for i in range(0, 27):\n",
    "    #Select the model\n",
    "    #modelname = 'model' + str(i)\n",
    "    #Test the model. Pass all the test data, not one by one returns labels of all the test data\n",
    "    print(\"Model accuracy results and info for player position: \" + col_names[i])\n",
    "    predictions = models[i].predict(X_test)\n",
    "    test_labels = y_test[col_names[i]]\n",
    "    print(\"The number of values in a test_label:\")\n",
    "    print(len(test_labels))\n",
    "    a = metrics.accuracy_score(test_labels, predictions)\n",
    "    print(\"Accuracy:\",a)\n",
    "    print(classification_report(test_labels, predictions))\n",
    "    f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "    all_f1scores.append(f1)\n",
    "    all_accuracies.append(a)\n",
    "    #Final shape should be 32 X 82717: 32 lists of 82717 length \n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "print(\"Length of all_f1scores and all_accuracies:\")\n",
    "print(len(all_f1scores))\n",
    "print(len(all_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(all_predictions, index = ['gk_positioning', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Averaging the weighted f1 scores to compute overall f1 score on the entire Logistic Regression Ensemble\n",
    "len(all_f1scores)\n",
    "s = 0.0\n",
    "for i in all_f1scores:\n",
    "    s = s + i\n",
    "final_acc = s / len(all_f1scores)\n",
    "print(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Uncomment when everything is ready \n",
    "df = pd.DataFrame(all_predictions, index = ['gk_diving', 'gk_handling', 'gk_kicking', 'gk_reflexes', 'gk_speed', 'gk_positioning', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb'])\n",
    "\n",
    "#Extracts all the labels for each test case \n",
    "#Based off of Apeksha's Code From Feature Extraction\n",
    "addT = df.T\n",
    "print(addT)\n",
    "labels=addT[addT.apply(lambda x: x == addT.max(axis = 1))] \n",
    "print(labels)\n",
    "\n",
    "classes=[]\n",
    "\n",
    "#Write all labels to this file\n",
    "outputFile = open('SplitTrainTestlogisticregressionensembleclassresults.txt','w')\n",
    "\n",
    "for i in range(labels.shape[0]):\n",
    "    l=list(labels.columns[np.isfinite(labels.iloc[i])])\n",
    "    print(l)\n",
    "    formatted_l=map(lambda x:x+' ', l)\n",
    "    outputFile.writelines(\"ID: \" + str(i) + \", Total Classes: \" + str(len(l)) + \" Classes: \")\n",
    "    outputFile.writelines(formatted_l)\n",
    "    outputFile.writelines('\\n')\n",
    "    #for i in l:\n",
    "    #    outputFile.write(i)\n",
    "    #    outputFile.write('\\n')\n",
    "    classes.append(l)\n",
    "    #Save the classes to a file\n",
    "print(len(classes))\n",
    "print(classes)\n",
    "outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
