{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Juliana Shihadeh \n",
    "#Pattern Recognition and Data Mining \n",
    "#Validation Testing\n",
    "#The K-Fold Validation below is Apeksha's code for the K-Fold Validation with a few minor edits I made to it to fit my models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Logistic Regression Ensemble Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def LogisticRegressionEnsemble(X_train, y_train):\n",
    "    models = []\n",
    "    for i in range(0, 27):\n",
    "        modelname = 'LRModel' + str(i)\n",
    "        #Add code above in here\n",
    "\n",
    "        #Change the last two lines so they save to separate models\n",
    "        logreg = LogisticRegression(solver='lbfgs', max_iter = 100000)\n",
    "        test_labels = y_train[col_names[i]]\n",
    "        modelname = logreg.fit(X_train, test_labels)\n",
    "\n",
    "        #At the end, append to the list of models\n",
    "        models.append(modelname)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Random Forest Ensemble Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def RandomForestEnsemble(X_train, y_train):    \n",
    "    #Train Random Forest Models on all columns\n",
    "    models = []\n",
    "    for i in range(0, 27):\n",
    "        model = RandomForestClassifier(n_estimators=100, \n",
    "                                   bootstrap = True,\n",
    "                                   max_features = 'sqrt')\n",
    "        train_labels = y_train[col_names[i]]\n",
    "        #train = All the features of our data\n",
    "        #Fits the features to the labels\n",
    "        model = model.fit(X_train, train_labels)\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "def test_model(models, X_test, y_test):\n",
    "    #Method 1: Predict results of all the tests, then loop through and print out all the results\n",
    "    #Run each test through every Random Forest Model and append the result\n",
    "    #Two separate loops\n",
    "    #O(n): 32 + numRecords (test cases)\n",
    "    all_predictions = []\n",
    "    all_accuracies = []\n",
    "    all_f1scores = []\n",
    "    for i in range(0, 27):\n",
    "        #Select the model\n",
    "        #modelname = 'model' + str(i)\n",
    "        #Test the model. Pass all the test data, not one by one returns labels of all the test data\n",
    "        predictions = models[i].predict(X_test)\n",
    "        #Final shape should be 32 X 82717: 32 lists of 82717 length \n",
    "        test_labels = y_test[col_names[i]]\n",
    "        print(\"The number of values in a test_label:\")\n",
    "        print(len(test_labels))\n",
    "        a = metrics.accuracy_score(test_labels, predictions)\n",
    "        print(\"Accuracy:\",a)\n",
    "        print(classification_report(test_labels, predictions))\n",
    "        f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "        all_f1scores.append(f1)\n",
    "        all_accuracies.append(a)\n",
    "        all_predictions.append(predictions)\n",
    "    #print(\"Length of all_f1scores and all_accuracies:\")\n",
    "    #print(len(all_f1scores))\n",
    "    #print(len(all_accuracies))\n",
    "    len(all_f1scores)\n",
    "    s = 0.0\n",
    "    #Compute the overall f1-score of the model by taking the average of all the f1-scores of the random forests\n",
    "    for i in all_f1scores:\n",
    "        s = s + i\n",
    "    final_acc = s / len(all_f1scores)\n",
    "    print(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gk_positioning  ls  st  rs  lw  lf  cf  rf  rw  lam  ...  lwb  ldm  cdm  \\\n",
      "0               0   0   0   0   1   0   0   0   1    1  ...    0    0    0   \n",
      "1               0   1   1   1   0   1   1   1   0    0  ...    0    0    0   \n",
      "2               0   0   0   0   1   0   0   0   1    1  ...    0    0    0   \n",
      "3               0   1   1   1   0   0   0   0   0    0  ...    0    0    0   \n",
      "4               1   0   0   0   0   0   0   0   0    0  ...    0    0    0   \n",
      "\n",
      "   rdm  rwb  lb  lcb  cb  rcb  rb  \n",
      "0    0    0   0    0   0    0   0  \n",
      "1    0    0   0    0   0    0   0  \n",
      "2    0    0   0    0   0    0   0  \n",
      "3    0    0   0    0   0    0   0  \n",
      "4    0    0   0    0   0    0   0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "   attacking_crossing  attacking_finishing  attacking_heading_accuracy  \\\n",
      "0                  84                   91                          71   \n",
      "1                  83                   98                          86   \n",
      "2                  80                   87                          50   \n",
      "3                  76                   91                          76   \n",
      "4                  25                   25                          25   \n",
      "\n",
      "   attacking_short_passing  attacking_volleys  skill_dribbling  skill_curve  \\\n",
      "0                       89                 80               95           91   \n",
      "1                       82                 89               96           88   \n",
      "2                       88                 88               93           85   \n",
      "3                       82                 95               88           80   \n",
      "4                       42                 25               25           25   \n",
      "\n",
      "   skill_fk_accuracy  skill_long_passing  skill_ball_control  ...  weak_foot  \\\n",
      "0                 94                  76                  96  ...          3   \n",
      "1                 79                  72                  89  ...          4   \n",
      "2                 82                  79                  91  ...          2   \n",
      "3                 80                  80                  90  ...          4   \n",
      "4                 25                  41                  31  ...          4   \n",
      "\n",
      "   skill_moves  body_type  contract_valid_until  pace  shooting  passing  \\\n",
      "0            4          0                2018.0  93.0      89.0     86.0   \n",
      "1            5          0                2018.0  93.0      93.0     81.0   \n",
      "2            4          0                2017.0  93.0      86.0     83.0   \n",
      "3            4          0                2016.0  76.0      91.0     81.0   \n",
      "4            1          0                2019.0   0.0       0.0      0.0   \n",
      "\n",
      "   dribbling  defending  physic  \n",
      "0       96.0       27.0    63.0  \n",
      "1       91.0       32.0    79.0  \n",
      "2       92.0       32.0    64.0  \n",
      "3       86.0       34.0    86.0  \n",
      "4        0.0        0.0     0.0  \n",
      "\n",
      "[5 rows x 105 columns]\n",
      "['gk_positioning', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb']\n",
      "27\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n",
      "66173\n"
     ]
    }
   ],
   "source": [
    "#Divide the Train Set into a Train/Test set for validation testing\n",
    "#Extract all the Train/Test Split labels and the column names\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_labels = pd.read_csv('/Users/julianashihadeh/Desktop/GroupProject/Player_Position_Prediction/FridayVersion/Player_Position_Prediction/train_labels.csv', sep=\",\",header=\"infer\", low_memory = False)         \n",
    "print(training_labels.head())\n",
    "\n",
    "#Extracting all the training data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "training_data = pd.read_csv('/Users/julianashihadeh/Desktop/GroupProject/Player_Position_Prediction/SundayVersion/Player_Position_Prediction/train1.csv', sep=\",\",header=\"infer\", low_memory=False)\n",
    "print(training_data.head())\n",
    "\n",
    "#Split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, training_labels, test_size = 0.2, random_state=11)\n",
    "                                                   \n",
    "#print(y_train)                                                    \n",
    "col_names = y_train.columns.values.tolist()\n",
    "print(col_names)\n",
    "print(len(col_names))\n",
    "\n",
    "for i in range(len(col_names)):\n",
    "    train_labels = y_train[col_names[i]]\n",
    "    #print(train_labels)\n",
    "    print(len(train_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "#Train Random Forest Ensemble\n",
    "models = RandomForestEnsemble(X_train, y_train)\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "#Train LogisticRegressionEnsemble\n",
    "LRE_models = LogisticRegressionEnsemble(X_train, y_train)\n",
    "print(len(LRE_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Fold on all models\n",
    "all_models = [models, LRE_models]\n",
    "\n",
    "for model in all_models:\n",
    "    for one in model:        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounds: :::::::\n",
      "0\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "K-Fold Validation results\n",
      "1.0\n",
      "rounds: :::::::\n",
      "1\n",
      "[ 0.9802055   0.9802055   0.98141432  0.97748224  0.978389    0.97733112\n",
      "  0.98156264  0.9789935   0.97778449  0.98050476]\n",
      "K-Fold Validation results\n",
      "0.979387308065\n",
      "rounds: :::::::\n",
      "2\n",
      "[ 0.97914778  0.98080991  0.98126322  0.97823787  0.97959801  0.97763337\n",
      "  0.98231827  0.97823787  0.97748224  0.98095814]\n",
      "K-Fold Validation results\n",
      "0.979568668265\n",
      "rounds: :::::::\n",
      "3\n",
      "[ 0.97854337  0.9803566   0.9803566   0.978389    0.97944688  0.97778449\n",
      "  0.98110926  0.97884238  0.97748224  0.98065589]\n",
      "K-Fold Validation results\n",
      "0.979296671353\n",
      "rounds: :::::::\n",
      "4\n",
      "[ 0.9407676   0.93895437  0.94242974  0.94030527  0.93849176  0.93924739\n",
      "  0.94332779  0.94559468  0.93924739  0.94378117]\n",
      "K-Fold Validation results\n",
      "0.941214717369\n",
      "rounds: :::::::\n",
      "5\n",
      "[ 0.94394077  0.94877607  0.95179813  0.94650144  0.94846607  0.94635031\n",
      "  0.94891945  0.95027958  0.94695481  0.94967508]\n",
      "K-Fold Validation results\n",
      "0.948166170244\n",
      "rounds: :::::::\n",
      "6\n",
      "[ 0.94394077  0.94862496  0.95013599  0.94650144  0.94786157  0.94665256\n",
      "  0.94831495  0.95133746  0.94665256  0.95133746]\n",
      "K-Fold Validation results\n",
      "0.948135972469\n",
      "rounds: :::::::\n",
      "7\n",
      "[ 0.94454518  0.94938048  0.95104261  0.94680369  0.94786157  0.94589693\n",
      "  0.94967508  0.95118634  0.94801269  0.95118634]\n",
      "K-Fold Validation results\n",
      "0.948559090702\n",
      "rounds: :::::::\n",
      "8\n",
      "[ 0.94182532  0.93834995  0.93925657  0.93970077  0.94075865  0.936376\n",
      "  0.94181653  0.94287441  0.93849176  0.94499018]\n",
      "K-Fold Validation results\n",
      "0.940444016445\n",
      "rounds: :::::::\n",
      "9\n",
      "[ 0.94258084  0.94137202  0.94212753  0.94211878  0.94740819  0.94408342\n",
      "  0.94635031  0.94438567  0.94136316  0.94226991]\n",
      "K-Fold Validation results\n",
      "0.94340598337\n",
      "rounds: :::::::\n",
      "10\n",
      "[ 0.94363856  0.93850106  0.94288305  0.9398519   0.94544355  0.94302554\n",
      "  0.94559468  0.94226991  0.9410609   0.94257216]\n",
      "K-Fold Validation results\n",
      "0.942484131439\n",
      "rounds: :::::::\n",
      "11\n",
      "[ 0.9407676   0.94091871  0.94288305  0.94121203  0.94771044  0.94363004\n",
      "  0.9486172   0.9451413   0.94166541  0.94317667]\n",
      "K-Fold Validation results\n",
      "0.943572244683\n",
      "rounds: :::::::\n",
      "12\n",
      "[ 0.92172862  0.92459958  0.92157752  0.92398368  0.92383255  0.92504156\n",
      "  0.9229258   0.92398368  0.92201904  0.92489043]\n",
      "K-Fold Validation results\n",
      "0.923458245342\n",
      "rounds: :::::::\n",
      "13\n",
      "[ 0.96645512  0.96630402  0.96721064  0.96690343  0.96645005  0.96448542\n",
      "  0.97098383  0.96569442  0.96796131  0.95934714]\n",
      "K-Fold Validation results\n",
      "0.966179538011\n",
      "rounds: :::::::\n",
      "14\n",
      "[ 0.96600181  0.96358416  0.9655485   0.96690343  0.96690343  0.96433429\n",
      "  0.97189058  0.96448542  0.96629893  0.96010277]\n",
      "K-Fold Validation results\n",
      "0.965605332711\n",
      "rounds: :::::::\n",
      "15\n",
      "[ 0.96494409  0.96569961  0.96433968  0.96841469  0.96584555  0.96388091\n",
      "  0.97053045  0.96493879  0.96569442  0.9608584 ]\n",
      "K-Fold Validation results\n",
      "0.965514659462\n",
      "rounds: :::::::\n",
      "16\n",
      "[ 0.92263524  0.92369296  0.92218193  0.92277467  0.92443706  0.92428593\n",
      "  0.92549494  0.92504156  0.92201904  0.92473931]\n",
      "K-Fold Validation results\n",
      "0.923730262806\n",
      "rounds: :::::::\n",
      "17\n",
      "[ 0.95844666  0.95859776  0.95089151  0.95345323  0.94982621  0.95451111\n",
      "  0.95617349  0.95451111  0.95451111  0.95163972]\n",
      "K-Fold Validation results\n",
      "0.954256189573\n",
      "rounds: :::::::\n",
      "18\n",
      "[ 0.96010879  0.96252644  0.95995769  0.95995164  0.95481336  0.9573825\n",
      "  0.95859151  0.96025389  0.96645005  0.95526674]\n",
      "K-Fold Validation results\n",
      "0.959530261555\n",
      "rounds: :::::::\n",
      "19\n",
      "[ 0.96131762  0.96192203  0.95980659  0.9608584   0.95692912  0.95874263\n",
      "  0.96040502  0.96055614  0.96660118  0.95526674]\n",
      "K-Fold Validation results\n",
      "0.960240546377\n",
      "rounds: :::::::\n",
      "20\n",
      "[ 0.96146872  0.96252644  0.96192203  0.96055614  0.95708025  0.95617349\n",
      "  0.95874263  0.95904488  0.9655433   0.9526976 ]\n",
      "K-Fold Validation results\n",
      "0.959575549083\n",
      "rounds: :::::::\n",
      "21\n",
      "[ 0.95602901  0.95965549  0.95149592  0.95466223  0.95118634  0.95526674\n",
      "  0.95420886  0.95723137  0.95435998  0.9526976 ]\n",
      "K-Fold Validation results\n",
      "0.954679353477\n",
      "rounds: :::::::\n",
      "22\n",
      "[ 0.95104261  0.94877607  0.945754    0.94257216  0.94408342  0.94665256\n",
      "  0.95012846  0.95043071  0.94378117  0.94619918]\n",
      "K-Fold Validation results\n",
      "0.946942034567\n",
      "rounds: :::::::\n",
      "23\n",
      "[ 0.96479299  0.96841946  0.96146872  0.96388091  0.96493879  0.96660118\n",
      "  0.96735681  0.96735681  0.96690343  0.96116065]\n",
      "K-Fold Validation results\n",
      "0.965287975198\n",
      "rounds: :::::::\n",
      "24\n",
      "[ 0.96358416  0.96781505  0.96071321  0.96463654  0.96403204  0.96690343\n",
      "  0.96781019  0.96826356  0.96599668  0.96191628]\n",
      "K-Fold Validation results\n",
      "0.965167113308\n",
      "rounds: :::::::\n",
      "25\n",
      "[ 0.96479299  0.96630402  0.96358416  0.96448542  0.96539217  0.96645005\n",
      "  0.96856582  0.96660118  0.96811244  0.96025389]\n",
      "K-Fold Validation results\n",
      "0.965454213674\n",
      "rounds: :::::::\n",
      "26\n",
      "[ 0.95013599  0.94832276  0.94666062  0.94347892  0.94740819  0.94740819\n",
      "  0.95012846  0.9492217   0.94272329  0.94846607]\n",
      "K-Fold Validation results\n",
      "0.947395419082\n",
      "0.956194506246\n"
     ]
    }
   ],
   "source": [
    "#K-Fold For Random Forest Ensemble Model\n",
    "from sklearn import model_selection\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "    \n",
    "count = 0\n",
    "total_results = 0\n",
    "for i in models:\n",
    "    print(\"rounds: :::::::\")\n",
    "    print(count)\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=0.11)\n",
    "    \n",
    "    #K-Fold for each random forest in the ensemble\n",
    "    train_labels = y_train[col_names[count]]\n",
    "    cv_results = model_selection.cross_val_score(i, X_train, train_labels, cv=kfold, scoring=scoring)\n",
    "    \n",
    "    print(cv_results)\n",
    "    avg_result = np.average(cv_results)\n",
    "    \n",
    "    results.append(avg_result)\n",
    "    print(\"K-Fold Validation results\")\n",
    "    print(avg_result)\n",
    "    total_results = total_results + avg_result\n",
    "    \n",
    "    count += 1\n",
    "    #names.append(name)  \n",
    "    \n",
    "final_kfold_result = total_results/len(models)\n",
    "print(final_kfold_result)\n",
    "#compare_f1_scores(names,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounds: :::::::\n",
      "0\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "K-Fold Validation results\n",
      "1.0\n",
      "rounds: :::::::\n",
      "1\n",
      "[ 0.98156543  0.97718344  0.9800544   0.97944688  0.98110926  0.98005138\n",
      "  0.9830739   0.97914463  0.98080701  0.98262052]\n",
      "K-Fold Validation results\n",
      "0.980505685307\n",
      "rounds: :::::::\n",
      "2\n",
      "[ 0.98171653  0.97703234  0.97975219  0.97944688  0.98110926  0.98005138\n",
      "  0.9830739   0.97914463  0.98065589  0.98262052]\n",
      "K-Fold Validation results\n",
      "0.980460352107\n",
      "rounds: :::::::\n",
      "3\n",
      "[ 0.98171653  0.97718344  0.97975219  0.97944688  0.98110926  0.98005138\n",
      "  0.9830739   0.97914463  0.98065589  0.98262052]\n",
      "K-Fold Validation results\n",
      "0.980475462413\n",
      "rounds: :::::::\n",
      "4\n",
      "[ 0.93532789  0.93366576  0.9304926   0.93501587  0.93607375  0.93063322\n",
      "  0.93788726  0.94015415  0.93320236  0.93410911]\n",
      "K-Fold Validation results\n",
      "0.934656196369\n",
      "rounds: :::::::\n",
      "5\n",
      "[ 0.93699003  0.94122091  0.94137202  0.94060753  0.9404564   0.94211878\n",
      "  0.94302554  0.94211878  0.93924739  0.94030527]\n",
      "K-Fold Validation results\n",
      "0.940746265937\n",
      "rounds: :::::::\n",
      "6\n",
      "[ 0.93699003  0.94122091  0.94137202  0.94060753  0.9404564   0.94181653\n",
      "  0.94302554  0.94211878  0.93924739  0.94030527]\n",
      "K-Fold Validation results\n",
      "0.940716040759\n",
      "rounds: :::::::\n",
      "7\n",
      "[ 0.93699003  0.94122091  0.94137202  0.94060753  0.9404564   0.94181653\n",
      "  0.94257216  0.94211878  0.93924739  0.94030527]\n",
      "K-Fold Validation results\n",
      "0.940670702993\n",
      "rounds: :::::::\n",
      "8\n",
      "[ 0.93532789  0.93366576  0.9304926   0.93501587  0.93607375  0.93063322\n",
      "  0.93788726  0.94015415  0.93320236  0.93410911]\n",
      "K-Fold Validation results\n",
      "0.934656196369\n",
      "rounds: :::::::\n",
      "9\n",
      "[ 0.92822605  0.92429737  0.92928377  0.92927308  0.93471362  0.93123772\n",
      "  0.93002871  0.93078434  0.93078434  0.92881971]\n",
      "K-Fold Validation results\n",
      "0.92974487219\n",
      "rounds: :::::::\n",
      "10\n",
      "[ 0.92822605  0.92429737  0.92928377  0.92927308  0.93471362  0.93123772\n",
      "  0.93002871  0.93078434  0.93078434  0.92881971]\n",
      "K-Fold Validation results\n",
      "0.92974487219\n",
      "rounds: :::::::\n",
      "11\n",
      "[ 0.92777274  0.92429737  0.92928377  0.92927308  0.93471362  0.93123772\n",
      "  0.93002871  0.93017984  0.93078434  0.92881971]\n",
      "K-Fold Validation results\n",
      "0.929639090919\n",
      "rounds: :::::::\n",
      "12\n",
      "[ 0.89951647  0.8960411   0.89724992  0.89693214  0.89995466  0.90086142\n",
      "  0.90025691  0.90222155  0.90025691  0.90207042]\n",
      "K-Fold Validation results\n",
      "0.899536152222\n",
      "rounds: :::::::\n",
      "13\n",
      "[ 0.94348746  0.94907827  0.94726503  0.94181653  0.94725707  0.94816382\n",
      "  0.94816382  0.95043071  0.94755932  0.94302554]\n",
      "K-Fold Validation results\n",
      "0.946624756978\n",
      "rounds: :::::::\n",
      "14\n",
      "[ 0.94348746  0.94907827  0.94726503  0.94181653  0.94665256  0.94816382\n",
      "  0.94816382  0.95043071  0.94755932  0.94302554]\n",
      "K-Fold Validation results\n",
      "0.946564306623\n",
      "rounds: :::::::\n",
      "15\n",
      "[ 0.94348746  0.94907827  0.94726503  0.94181653  0.94665256  0.94816382\n",
      "  0.94831495  0.95043071  0.94755932  0.94347892]\n",
      "K-Fold Validation results\n",
      "0.946624756978\n",
      "rounds: :::::::\n",
      "16\n",
      "[ 0.89951647  0.8960411   0.89724992  0.89693214  0.89995466  0.90207042\n",
      "  0.90025691  0.90222155  0.90025691  0.90207042]\n",
      "K-Fold Validation results\n",
      "0.899657052932\n",
      "rounds: :::::::\n",
      "17\n",
      "[ 0.94258084  0.9456029   0.93834995  0.94000302  0.93849176  0.94015415\n",
      "  0.93803839  0.94332779  0.936376    0.94000302]\n",
      "K-Fold Validation results\n",
      "0.94029278323\n",
      "rounds: :::::::\n",
      "18\n",
      "[ 0.94620731  0.9454518   0.9456029   0.9451413   0.94060753  0.94423455\n",
      "  0.94650144  0.94635031  0.94544355  0.93834064]\n",
      "K-Fold Validation results\n",
      "0.944388132658\n",
      "rounds: :::::::\n",
      "19\n",
      "[ 0.94620731  0.94499849  0.9456029   0.9451413   0.94060753  0.94423455\n",
      "  0.94650144  0.94635031  0.94544355  0.93834064]\n",
      "K-Fold Validation results\n",
      "0.944342801742\n",
      "rounds: :::::::\n",
      "20\n",
      "[ 0.94696283  0.94499849  0.9456029   0.9451413   0.94060753  0.94423455\n",
      "  0.94650144  0.94635031  0.94544355  0.93834064]\n",
      "K-Fold Validation results\n",
      "0.944418353269\n",
      "rounds: :::::::\n",
      "21\n",
      "[ 0.94318525  0.9456029   0.93834995  0.94000302  0.93849176  0.94015415\n",
      "  0.93803839  0.94332779  0.936376    0.94000302]\n",
      "K-Fold Validation results\n",
      "0.940353224451\n",
      "rounds: :::::::\n",
      "22\n",
      "[ 0.92671502  0.92867936  0.92384406  0.92262355  0.92640169  0.9270062\n",
      "  0.92141454  0.9241348   0.9241348   0.92398368]\n",
      "K-Fold Validation results\n",
      "0.92489377001\n",
      "rounds: :::::::\n",
      "23\n",
      "[ 0.97068601  0.97189483  0.96872167  0.96871694  0.97173946  0.96932144\n",
      "  0.96992595  0.97204171  0.97461085  0.96660118]\n",
      "K-Fold Validation results\n",
      "0.970426004194\n",
      "rounds: :::::::\n",
      "24\n",
      "[ 0.97068601  0.97189483  0.96872167  0.96871694  0.97173946  0.96932144\n",
      "  0.96992595  0.97204171  0.97461085  0.96660118]\n",
      "K-Fold Validation results\n",
      "0.970426004194\n",
      "rounds: :::::::\n",
      "25\n",
      "[ 0.97068601  0.97189483  0.96872167  0.96871694  0.97173946  0.96932144\n",
      "  0.96992595  0.97204171  0.97461085  0.96660118]\n",
      "K-Fold Validation results\n",
      "0.970426004194\n",
      "rounds: :::::::\n",
      "26\n",
      "[ 0.92671502  0.92867936  0.92384406  0.92262355  0.92640169  0.9270062\n",
      "  0.92141454  0.9241348   0.92322805  0.92398368]\n",
      "K-Fold Validation results\n",
      "0.924803094477\n",
      "0.94577010873\n"
     ]
    }
   ],
   "source": [
    "#K-Fold for Logist Regression Ensemble Model\n",
    "from sklearn import model_selection\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "    \n",
    "count = 0\n",
    "total_results = 0\n",
    "for i in LRE_models:\n",
    "    print(\"rounds: :::::::\")\n",
    "    print(count)\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=0.11)\n",
    "    \n",
    "    #K-Fold for each random forest in the ensemble\n",
    "    train_labels = y_train[col_names[count]]\n",
    "    cv_results = model_selection.cross_val_score(i, X_train, train_labels, cv=kfold, scoring=scoring)\n",
    "    \n",
    "    print(cv_results)\n",
    "    avg_result = np.average(cv_results)\n",
    "    \n",
    "    results.append(avg_result)\n",
    "    print(\"K-Fold Validation results\")\n",
    "    print(avg_result)\n",
    "    total_results = total_results + avg_result\n",
    "    \n",
    "    count += 1\n",
    "    #names.append(name)  \n",
    "    \n",
    "final_kfold_result = total_results/len(models)\n",
    "print(final_kfold_result)\n",
    "#compare_f1_scores(names,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14695\n",
      "           1       1.00      1.00      1.00      1849\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     16544\n",
      "   macro avg       1.00      1.00      1.00     16544\n",
      "weighted avg       1.00      1.00      1.00     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.980415860735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     14201\n",
      "           1       0.96      0.90      0.93      2343\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     16544\n",
      "   macro avg       0.97      0.95      0.96     16544\n",
      "weighted avg       0.98      0.98      0.98     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.979146518375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     14201\n",
      "           1       0.95      0.90      0.92      2343\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     16544\n",
      "   macro avg       0.97      0.95      0.96     16544\n",
      "weighted avg       0.98      0.98      0.98     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.979871856867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     14201\n",
      "           1       0.95      0.90      0.93      2343\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     16544\n",
      "   macro avg       0.97      0.95      0.96     16544\n",
      "weighted avg       0.98      0.98      0.98     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.941610251451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96     13434\n",
      "           1       0.87      0.81      0.84      3110\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.91      0.89      0.90     16544\n",
      "weighted avg       0.94      0.94      0.94     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.947171179884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     15425\n",
      "           1       0.83      0.28      0.41      1119\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.89      0.64      0.69     16544\n",
      "weighted avg       0.94      0.95      0.93     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.947896518375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     15425\n",
      "           1       0.84      0.28      0.42      1119\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.90      0.64      0.70     16544\n",
      "weighted avg       0.94      0.95      0.94     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.948319632495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     15425\n",
      "           1       0.83      0.29      0.44      1119\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.89      0.65      0.70     16544\n",
      "weighted avg       0.94      0.95      0.94     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.940764023211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96     13434\n",
      "           1       0.87      0.80      0.84      3110\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.91      0.89      0.90     16544\n",
      "weighted avg       0.94      0.94      0.94     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.942940038685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     14607\n",
      "           1       0.86      0.61      0.71      1937\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.91      0.80      0.84     16544\n",
      "weighted avg       0.94      0.94      0.94     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.943544487427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     14607\n",
      "           1       0.87      0.61      0.72      1937\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.91      0.80      0.84     16544\n",
      "weighted avg       0.94      0.94      0.94     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.94457205029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     14607\n",
      "           1       0.87      0.62      0.72      1937\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.91      0.80      0.85     16544\n",
      "weighted avg       0.94      0.94      0.94     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.924987911025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     13882\n",
      "           1       0.84      0.66      0.74      2662\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     16544\n",
      "   macro avg       0.89      0.82      0.85     16544\n",
      "weighted avg       0.92      0.92      0.92     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.968689555126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     15461\n",
      "           1       0.88      0.60      0.72      1083\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     16544\n",
      "   macro avg       0.93      0.80      0.85     16544\n",
      "weighted avg       0.97      0.97      0.97     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.967964216634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     15461\n",
      "           1       0.87      0.60      0.71      1083\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     16544\n",
      "   macro avg       0.92      0.80      0.85     16544\n",
      "weighted avg       0.97      0.97      0.97     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.967420212766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     15461\n",
      "           1       0.87      0.59      0.70      1083\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     16544\n",
      "   macro avg       0.92      0.79      0.84     16544\n",
      "weighted avg       0.97      0.97      0.96     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.924685686654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     13882\n",
      "           1       0.84      0.65      0.74      2662\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     16544\n",
      "   macro avg       0.89      0.81      0.85     16544\n",
      "weighted avg       0.92      0.92      0.92     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.953034332689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     14450\n",
      "           1       0.87      0.74      0.80      2094\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.92      0.86      0.89     16544\n",
      "weighted avg       0.95      0.95      0.95     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.961436170213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     15061\n",
      "           1       0.89      0.65      0.75      1483\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     16544\n",
      "   macro avg       0.93      0.82      0.87     16544\n",
      "weighted avg       0.96      0.96      0.96     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.962040618956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     15061\n",
      "           1       0.90      0.65      0.75      1483\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     16544\n",
      "   macro avg       0.93      0.82      0.87     16544\n",
      "weighted avg       0.96      0.96      0.96     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.961617504836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     15061\n",
      "           1       0.89      0.65      0.75      1483\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     16544\n",
      "   macro avg       0.93      0.82      0.87     16544\n",
      "weighted avg       0.96      0.96      0.96     16544\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.953457446809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     14450\n",
      "           1       0.87      0.74      0.80      2094\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.92      0.86      0.89     16544\n",
      "weighted avg       0.95      0.95      0.95     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.948500967118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     14728\n",
      "           1       0.82      0.68      0.74      1816\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.89      0.83      0.86     16544\n",
      "weighted avg       0.95      0.95      0.95     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.963430851064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     12306\n",
      "           1       0.95      0.90      0.93      4238\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     16544\n",
      "   macro avg       0.96      0.94      0.95     16544\n",
      "weighted avg       0.96      0.96      0.96     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.964095744681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     12306\n",
      "           1       0.96      0.90      0.93      4238\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     16544\n",
      "   macro avg       0.96      0.94      0.95     16544\n",
      "weighted avg       0.96      0.96      0.96     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.964277079304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     12306\n",
      "           1       0.95      0.90      0.93      4238\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     16544\n",
      "   macro avg       0.96      0.94      0.95     16544\n",
      "weighted avg       0.96      0.96      0.96     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.949044970986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     14728\n",
      "           1       0.82      0.69      0.75      1816\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.89      0.83      0.86     16544\n",
      "weighted avg       0.95      0.95      0.95     16544\n",
      "\n",
      "0.953545235976\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Ensemble Test with the Test Split Set\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "test_model(models, X_test, y_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14695\n",
      "           1       1.00      1.00      1.00      1849\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     16544\n",
      "   macro avg       1.00      1.00      1.00     16544\n",
      "weighted avg       1.00      1.00      1.00     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.979690522244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     14201\n",
      "           1       0.93      0.92      0.93      2343\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     16544\n",
      "   macro avg       0.96      0.96      0.96     16544\n",
      "weighted avg       0.98      0.98      0.98     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.979690522244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     14201\n",
      "           1       0.93      0.92      0.93      2343\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     16544\n",
      "   macro avg       0.96      0.96      0.96     16544\n",
      "weighted avg       0.98      0.98      0.98     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.979690522244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     14201\n",
      "           1       0.93      0.92      0.93      2343\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     16544\n",
      "   macro avg       0.96      0.96      0.96     16544\n",
      "weighted avg       0.98      0.98      0.98     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.932422630561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     13434\n",
      "           1       0.83      0.81      0.82      3110\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     16544\n",
      "   macro avg       0.89      0.89      0.89     16544\n",
      "weighted avg       0.93      0.93      0.93     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.940220019342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     15425\n",
      "           1       0.62      0.31      0.41      1119\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.78      0.65      0.69     16544\n",
      "weighted avg       0.93      0.94      0.93     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.940220019342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     15425\n",
      "           1       0.62      0.31      0.41      1119\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.78      0.65      0.69     16544\n",
      "weighted avg       0.93      0.94      0.93     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.940220019342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     15425\n",
      "           1       0.62      0.31      0.41      1119\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.78      0.65      0.69     16544\n",
      "weighted avg       0.93      0.94      0.93     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.932422630561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     13434\n",
      "           1       0.83      0.81      0.82      3110\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     16544\n",
      "   macro avg       0.89      0.89      0.89     16544\n",
      "weighted avg       0.93      0.93      0.93     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.930186170213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     14607\n",
      "           1       0.74      0.61      0.67      1937\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     16544\n",
      "   macro avg       0.85      0.79      0.82     16544\n",
      "weighted avg       0.93      0.93      0.93     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.930186170213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     14607\n",
      "           1       0.74      0.61      0.67      1937\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     16544\n",
      "   macro avg       0.85      0.79      0.82     16544\n",
      "weighted avg       0.93      0.93      0.93     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.930186170213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     14607\n",
      "           1       0.74      0.61      0.67      1937\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     16544\n",
      "   macro avg       0.85      0.79      0.82     16544\n",
      "weighted avg       0.93      0.93      0.93     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.897969052224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     13882\n",
      "           1       0.71      0.62      0.66      2662\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     16544\n",
      "   macro avg       0.82      0.79      0.80     16544\n",
      "weighted avg       0.89      0.90      0.90     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.948621856867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     15461\n",
      "           1       0.64      0.48      0.55      1083\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.80      0.73      0.76     16544\n",
      "weighted avg       0.94      0.95      0.95     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.948621856867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     15461\n",
      "           1       0.64      0.48      0.55      1083\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.80      0.73      0.76     16544\n",
      "weighted avg       0.94      0.95      0.95     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.948621856867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     15461\n",
      "           1       0.64      0.48      0.55      1083\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.80      0.73      0.76     16544\n",
      "weighted avg       0.94      0.95      0.95     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.897969052224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     13882\n",
      "           1       0.71      0.62      0.66      2662\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     16544\n",
      "   macro avg       0.82      0.79      0.80     16544\n",
      "weighted avg       0.89      0.90      0.90     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.937681334623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96     14450\n",
      "           1       0.77      0.73      0.75      2094\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.86      0.85      0.86     16544\n",
      "weighted avg       0.94      0.94      0.94     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.945478723404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     15061\n",
      "           1       0.72      0.64      0.68      1483\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.84      0.81      0.82     16544\n",
      "weighted avg       0.94      0.95      0.94     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.945478723404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     15061\n",
      "           1       0.72      0.64      0.68      1483\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.84      0.81      0.82     16544\n",
      "weighted avg       0.94      0.95      0.94     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.945478723404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     15061\n",
      "           1       0.72      0.64      0.68      1483\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     16544\n",
      "   macro avg       0.84      0.81      0.82     16544\n",
      "weighted avg       0.94      0.95      0.94     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.937681334623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96     14450\n",
      "           1       0.77      0.73      0.75      2094\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16544\n",
      "   macro avg       0.86      0.85      0.86     16544\n",
      "weighted avg       0.94      0.94      0.94     16544\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.924262572534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96     14728\n",
      "           1       0.67      0.61      0.64      1816\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     16544\n",
      "   macro avg       0.81      0.79      0.80     16544\n",
      "weighted avg       0.92      0.92      0.92     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.970623791103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     12306\n",
      "           1       0.95      0.94      0.94      4238\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     16544\n",
      "   macro avg       0.96      0.96      0.96     16544\n",
      "weighted avg       0.97      0.97      0.97     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.970623791103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     12306\n",
      "           1       0.95      0.94      0.94      4238\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     16544\n",
      "   macro avg       0.96      0.96      0.96     16544\n",
      "weighted avg       0.97      0.97      0.97     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.970623791103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     12306\n",
      "           1       0.95      0.94      0.94      4238\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     16544\n",
      "   macro avg       0.96      0.96      0.96     16544\n",
      "weighted avg       0.97      0.97      0.97     16544\n",
      "\n",
      "The number of values in a test_label:\n",
      "16544\n",
      "Accuracy: 0.924262572534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96     14728\n",
      "           1       0.67      0.61      0.64      1816\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     16544\n",
      "   macro avg       0.81      0.79      0.80     16544\n",
      "weighted avg       0.92      0.92      0.92     16544\n",
      "\n",
      "0.943170528242\n"
     ]
    }
   ],
   "source": [
    "#Test LogisticRegression Ensemble\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "test_model(LRE_models, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
