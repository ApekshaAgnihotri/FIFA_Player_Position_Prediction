{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Juliana \n",
    "#Logist Regression with RFE Draft Code\n",
    "#Based on https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Need to take in:\n",
    "#traindata\n",
    "#labels \n",
    "\n",
    "logreg = LogisticRegression()\n",
    "#how many attributes to keep:\n",
    "#Total of 95 features\n",
    "#Maybe keep 85?\n",
    "rfe = RFE(logreg, 85)\n",
    "rfe = rfe.fit(traindata, labels)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "\n",
    "#Based on rfe.ranking_ drop columns in the features extracted\n",
    "#for i in rfe.ranking_:\n",
    "    #drop i from the dataframe\n",
    "    #df.drop(columns=[i],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then run the model as following:\n",
    "#y: features\n",
    "#y = df\n",
    "#X: our labels\n",
    "#X = newdf (based on Gaurav's code)\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "\n",
    "#Check which values have a value less than 0.05 and drop them\n",
    "\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "\n",
    "#Fit the model?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "#X_train -> the dataframe of features extracted\n",
    "#y_train -> the dataframe of labels extracted\n",
    "#Create a logreg model for each model, have all the code loop 32 times\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the predictions\n",
    "y_pred = logreg1.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A confusion matrix to print out how many correct and incorrect predictions there are\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report of different accuracy calculations\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Training:\n",
    "for i in range(0, 32):\n",
    "    modelname = 'LRModel' + str(i)\n",
    "    #Add code above in here\n",
    "    \n",
    "    #Change the last two lines so they save to separate models\n",
    "    logreg = LogisticRegression()\n",
    "    modelname = logreg.fit(X_train, y_train)\n",
    "    \n",
    "    #At the end, append to the list of models\n",
    "    models.append(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Testing: \n",
    "all_predictions = []\n",
    "for i in range(0, 32):\n",
    "    #Select the model\n",
    "    #modelname = 'model' + str(i)\n",
    "    #Test the model. Pass all the test data, not one by one returns labels of all the test data\n",
    "    rf_predictions = models[i].predict(X_test)\n",
    "    #Final shape should be 32 X 82717: 32 lists of 82717 length \n",
    "    all_predictions.append(rf_predictions)\n",
    "#Uncomment when everything is ready \n",
    "df = pd.DataFrame(all_predictions, index = ['gk_diving', 'gk_handling', 'gk_kicking', 'gk_reflexes', 'gk_speed', 'gk_positioning', 'ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb'])\n",
    "\n",
    "\n",
    "#Extracts all the labels for each test case \n",
    "#Based off of Apeksha's Code From Feature Extraction\n",
    "addT = df.T\n",
    "print(addT)\n",
    "labels=addT[addT.apply(lambda x: x == addT.max(axis = 1))] \n",
    "print(labels)\n",
    "classes=[]\n",
    "# Getting the column names\n",
    "for i in range(labels.shape[0]):\n",
    "    l=list(labels.columns[np.isfinite(labels.iloc[i])])\n",
    "    print(l)\n",
    "    classes.append(l)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
